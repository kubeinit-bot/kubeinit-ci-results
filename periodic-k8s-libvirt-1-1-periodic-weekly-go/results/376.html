<!DOCTYPE html>
<html lang="en" class="layout-pf">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title></title>
    <link rel="stylesheet" href="../static/css/patternfly.min.css">
    <link rel="stylesheet" href="../static/css/ara.css">
    
    <link rel="shortcut icon" href="../static/images/favicon.ico">
    
    
</head>

<body>
    <div class="pf-c-page">
        <header role="banner" class="pf-c-page__header">
            <div class="pf-c-page__header-brand">
                <a class="pf-c-page__header-brand-link" href="../">
                    <img class="pf-c-brand" src="../static/images/logo.svg" alt="KubeInit job report">
                </a>
            </div>
            <div class="pf-c-page__header-nav">
                <nav class="pf-c-nav" aria-label="Global">
                    <button class="pf-c-nav__scroll-button" aria-label="Scroll left">
                        <i class="fas fa-angle-left" aria-hidden="true"></i>
                    </button>
                    <ul class="pf-c-nav__horizontal-list">
                        <li class="pf-c-nav__item">
                            
                            <a href="../" class="pf-c-nav__link">Playbooks</a>
                            
                        </li>
                        


                        <li class="pf-c-nav__item">
                            <a href="https://docs.kubeinit.com" class="pf-c-nav__link" target="_blank">Docs</a>
                        </li>
                    </ul>
                </nav>
            </div>
        </header>
        <main role="main" class="pf-c-page__main">
            <section class="pf-c-page__main-section pf-m-light">
                



<div class="pf-c-card pf-m-hoverable pf-c-alert pf-m-success pf-m-inline">

    <ul class="pf-c-data-list" role="list">
        <li class="pf-c-data-list__item">
            <div class="pf-c-data-list__item-row">
                <div class="pf-c-data-list__item-control pf-m-fit-content">
                    
<div class="pf-c-alert__icon" title="Playbook completed successfully">
    <i class="fas fa-check-circle" aria-hidden="true"></i>
</div>

                </div>
                <div class="pf-c-data-list__item-content">
                    <div class="pf-c-data-list__cell pf-m-fit-content">
                        <div style="padding-top:1em; white-space:nowrap;">
                            <span title="Date at which the playbook started">
                                <i class="fas fa-play-circle" aria-hidden="true"></i> 27 Apr 2021 04:18:39 +0200
                            </span><br>
                            <span title="Date at which the playbook ended">
                                <i class="fas fa-stop-circle" aria-hidden="true" title="Date at which the playbook ended"></i> 27 Apr 2021 05:00:48 +0200
                            </span>
                        </div>
                    </div>
                    <div class="pf-c-data-list__cell pf-m-fit-content">
                        <div style="padding-top:1em; white-space:nowrap;" title="Duration of the playbook">
                            <i class="fas fa-stopwatch" aria-hidden="true"></i> 00:42:08.33
                        </div>
                    </div>
                    <div class="pf-c-data-list__cell pf-m-fit-content">
                        <div style="padding-top:1em; white-space:nowrap;" title="Ansible version">
                            Ansible 2.10.8
                        </div>
                    </div>
                    <div class="pf-c-data-list__cell pf-m-flex-5">
                        <div style="padding-top:1em;" title="/root/builds/g-yZ6fMM/0/kubeinit/kubeinit/tmp/kubeinit/playbooks/k8s.yml">
                            <a href="../playbooks/1.html">
                                ...0/kubeinit/kubeinit/tmp/kubeinit/playbooks/k8s.yml
                            </a>
                        </div>
                    </div>
                    <div class="pf-c-data-list__cell pf-m-flex-1">
                        <div style="padding-top:1em;">
                            <a href="../playbooks/1.html#hosts">1 hosts</a>
                        </div>
                    </div>
                    <div class="pf-c-data-list__cell pf-m-flex-1">
                        <div style="padding-top:1em;">
                            <a href="../playbooks/1.html#plays">2 plays</a>
                        </div>
                    </div>
                    <div class="pf-c-data-list__cell pf-m-flex-1">
                        <div style="padding-top:1em;">
                            <a href="../playbooks/1.html#results">403 results</a>
                        </div>
                    </div>
                    <div class="pf-c-data-list__cell pf-m-flex-1">
                        <div style="padding-top:1em;">
                            <a href="../playbooks/1.html#files">26 files</a>
                        </div>
                    </div>
                    <div class="pf-c-data-list__cell pf-m-flex-1">
                        <div style="padding-top:1em;">
                            <a href="../playbooks/1.html#records">0 records</a>
                        </div>
                    </div>
                    <div class="pf-c-data-list__cell pf-m-flex-1">
                        <details id="cli-arguments-details">
                            <summary><a>CLI arguments</a></summary>
                            <table class="pf-c-table pf-m-compact pf-m-grid-md" role="grid" aria-label="cli-arguments" id="cli-arguments">
                                <thead>
                                    <tr role="row">
                                        <th role="columnheader" scope="col">Argument</th>
                                        <th role="columnheader" scope="col">Value</th>
                                    </tr>
                                </thead>
                                <tbody role="rowgroup">
                                    
                                </tbody>
                            </table>
                        </details>
                    </div>
                </div>
            </div>
            
            <div class="pf-c-data-list__item-row">
                <ul class="pf-c-chip-group pf-m-toolbar">
                    <li>
                        <h4 class="pf-c-chip-group__label">Playbook labels</h4>
                        <ul class="pf-c-chip-group">
                            
                            <li class="pf-c-chip" title="remote_user:root">
                                <span class="pf-c-chip__text">remote_user:root</span>
                                
                                
                                <a class="pf-c-button pf-m-plain" type="button" aria-label="Search for this label" disabled>
                                
                                    <i class="fas fa-search" aria-hidden="true"></i>
                                </a>
                            </li>
                            
                            <li class="pf-c-chip" title="check:False">
                                <span class="pf-c-chip__text">check:False</span>
                                
                                
                                <a class="pf-c-button pf-m-plain" type="button" aria-label="Search for this label" disabled>
                                
                                    <i class="fas fa-search" aria-hidden="true"></i>
                                </a>
                            </li>
                            
                            <li class="pf-c-chip" title="tags:all">
                                <span class="pf-c-chip__text">tags:all</span>
                                
                                
                                <a class="pf-c-button pf-m-plain" type="button" aria-label="Search for this label" disabled>
                                
                                    <i class="fas fa-search" aria-hidden="true"></i>
                                </a>
                            </li>
                            
                        </ul>
                    </li>
                </ul>
            </div>
            
        </li>
    </ul>
</div>




<div class="pf-c-card" style="margin: 1em 0;">
    <div class="pf-c-card__header pf-c-title pf-m-md">
        <h1><strong>Details</strong></h1>
        <ul class="pf-c-list">
            <li><strong>Task</strong>: ../../roles/kubeinit_k8s : debug</a></li>
            <li><strong>Action</strong>: ansible.builtin.debug</li>
            <li><strong>Path</strong>: <a href="../files/24.html#line-33">/root/builds/g-yZ6fMM/0/kubeinit/kubeinit/tmp/kubeinit/kubeinit/roles/kubeinit_k8s/tasks/30_configure_master_nodes.yml:33</a>
            <li><strong>Host</strong>: <a href="../hosts/1.html">hypervisor-01</a></li>
            <li><strong>Status</strong>: ok</li>
            <li><strong>Started</strong>: 27 Apr 2021 05:00:03 +0200</li>
            <li><strong>Ended</strong>: 27 Apr 2021 05:00:03 +0200</li>
            <li><strong>Duration</strong>: 00:00:00.04</li>
        </ul>
    </div>
    <div class="pf-c-card__body">
        <h1><strong>Result</strong></h1>
        <table class="pf-c-table pf-m-grid-md pf-m-compact" role="grid" id="result-details">
            <thead>
                <tr role="row">
                    <th role="columnheader" scope="col" class="pf-m-width-20">Field</th>
                    <th role="columnheader" scope="col" class="pf-m-width-80">Value</th>
                </tr>
            </thead>
            <tbody>
                
                <tr role="row">
                    <td role="cell" id="changed" data-label="changed" class="pf-m-width-20">
                        <a href="#changed">changed</a>
                    </td>
                    <td role="cell" data-label="Value" class="pf-m-width-80">
                        <div class="codehilite"><pre><span></span>False
</pre></div>

                    </td>
                </tr>
                
                <tr role="row">
                    <td role="cell" id="k8s_master_kubeadm_master_init_output" data-label="k8s_master_kubeadm_master_init_output" class="pf-m-width-20">
                        <a href="#k8s_master_kubeadm_master_init_output">k8s_master_kubeadm_master_init_output</a>
                    </td>
                    <td role="cell" data-label="Value" class="pf-m-width-80">
                        <div class="codehilite"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;changed&quot;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
    <span class="nt">&quot;cmd&quot;</span><span class="p">:</span> <span class="s2">&quot;kubeadm reset -f || true\nkubeadm init    --control-plane-endpoint \&quot;api.k8scluster.kubeinit.local:6443\&quot;    --upload-certs    --pod-network-cidr=10.244.0.0/16\n&quot;</span><span class="p">,</span>
    <span class="nt">&quot;delta&quot;</span><span class="p">:</span> <span class="s2">&quot;0:03:49.494609&quot;</span><span class="p">,</span>
    <span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="s2">&quot;2021-04-27 03:00:03.659919&quot;</span><span class="p">,</span>
    <span class="nt">&quot;failed&quot;</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
    <span class="nt">&quot;rc&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="s2">&quot;2021-04-27 02:56:14.165310&quot;</span><span class="p">,</span>
    <span class="nt">&quot;stderr&quot;</span><span class="p">:</span> <span class="s2">&quot;W0427 02:56:14.242841   63598 removeetcdmember.go:79] [reset] No kubeadm config, using etcd pod spec to get data directory\nW0427 02:56:14.260804   63598 cleanupnode.go:99] [reset] Failed to evaluate the \&quot;/var/lib/kubelet\&quot; directory. Skipping its unmount and cleanup: lstat /var/lib/kubelet: no such file or directory\nI0427 02:56:18.110854   63597 version.go:254] remote version is much newer: v1.21.0; falling back to: stable-1.20&quot;</span><span class="p">,</span>
    <span class="nt">&quot;stderr_lines&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;W0427 02:56:14.242841   63598 removeetcdmember.go:79] [reset] No kubeadm config, using etcd pod spec to get data directory&quot;</span><span class="p">,</span>
        <span class="s2">&quot;W0427 02:56:14.260804   63598 cleanupnode.go:99] [reset] Failed to evaluate the \&quot;/var/lib/kubelet\&quot; directory. Skipping its unmount and cleanup: lstat /var/lib/kubelet: no such file or directory&quot;</span><span class="p">,</span>
        <span class="s2">&quot;I0427 02:56:18.110854   63597 version.go:254] remote version is much newer: v1.21.0; falling back to: stable-1.20&quot;</span>
    <span class="p">],</span>
    <span class="nt">&quot;stdout&quot;</span><span class="p">:</span> <span class="s2">&quot;[preflight] Running pre-flight checks\n[reset] No etcd config found. Assuming external etcd\n[reset] Please, manually reset etcd to prevent further issues\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \&quot;/var/lib/kubelet\&quot;\n[reset] Deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n[reset] Deleting contents of stateful directories: [/var/lib/dockershim /var/run/kubernetes /var/lib/cni]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \&quot;iptables\&quot; command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system&#39;s IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\n[init] Using Kubernetes version: v1.20.6\n[preflight] Running pre-flight checks\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action in beforehand using &#39;kubeadm config images pull&#39;\n[certs] Using certificateDir folder \&quot;/etc/kubernetes/pki\&quot;\n[certs] Generating \&quot;ca\&quot; certificate and key\n[certs] Generating \&quot;apiserver\&quot; certificate and key\n[certs] apiserver serving cert is signed for DNS names [api.k8scluster.kubeinit.local k8s-master-01.k8scluster.kubeinit.local kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.0.0.1]\n[certs] Generating \&quot;apiserver-kubelet-client\&quot; certificate and key\n[certs] Generating \&quot;front-proxy-ca\&quot; certificate and key\n[certs] Generating \&quot;front-proxy-client\&quot; certificate and key\n[certs] Generating \&quot;etcd/ca\&quot; certificate and key\n[certs] Generating \&quot;etcd/server\&quot; certificate and key\n[certs] etcd/server serving cert is signed for DNS names [k8s-master-01.k8scluster.kubeinit.local localhost] and IPs [10.0.0.1 127.0.0.1 ::1]\n[certs] Generating \&quot;etcd/peer\&quot; certificate and key\n[certs] etcd/peer serving cert is signed for DNS names [k8s-master-01.k8scluster.kubeinit.local localhost] and IPs [10.0.0.1 127.0.0.1 ::1]\n[certs] Generating \&quot;etcd/healthcheck-client\&quot; certificate and key\n[certs] Generating \&quot;apiserver-etcd-client\&quot; certificate and key\n[certs] Generating \&quot;sa\&quot; key and public key\n[kubeconfig] Using kubeconfig folder \&quot;/etc/kubernetes\&quot;\n[kubeconfig] Writing \&quot;admin.conf\&quot; kubeconfig file\n[kubeconfig] Writing \&quot;kubelet.conf\&quot; kubeconfig file\n[kubeconfig] Writing \&quot;controller-manager.conf\&quot; kubeconfig file\n[kubeconfig] Writing \&quot;scheduler.conf\&quot; kubeconfig file\n[kubelet-start] Writing kubelet environment file with flags to file \&quot;/var/lib/kubelet/kubeadm-flags.env\&quot;\n[kubelet-start] Writing kubelet configuration to file \&quot;/var/lib/kubelet/config.yaml\&quot;\n[kubelet-start] Starting the kubelet\n[control-plane] Using manifest folder \&quot;/etc/kubernetes/manifests\&quot;\n[control-plane] Creating static Pod manifest for \&quot;kube-apiserver\&quot;\n[control-plane] Creating static Pod manifest for \&quot;kube-controller-manager\&quot;\n[control-plane] Creating static Pod manifest for \&quot;kube-scheduler\&quot;\n[etcd] Creating static Pod manifest for local etcd in \&quot;/etc/kubernetes/manifests\&quot;\n[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \&quot;/etc/kubernetes/manifests\&quot;. This can take up to 4m0s\n[kubelet-check] Initial timeout of 40s passed.\n[apiclient] All control plane components are healthy after 72.042992 seconds\n[upload-config] Storing the configuration used in ConfigMap \&quot;kubeadm-config\&quot; in the \&quot;kube-system\&quot; Namespace\n[kubelet] Creating a ConfigMap \&quot;kubelet-config-1.20\&quot; in namespace kube-system with the configuration for the kubelets in the cluster\n[upload-certs] Storing the certificates in Secret \&quot;kubeadm-certs\&quot; in the \&quot;kube-system\&quot; Namespace\n[upload-certs] Using certificate key:\n9a35db48225db308b55357b491956f4b1f0f2da14be9d9b5d9a7d6dde87064ae\n[mark-control-plane] Marking the node k8s-master-01.k8scluster.kubeinit.local as control-plane by adding the labels \&quot;node-role.kubernetes.io/master=&#39;&#39;\&quot; and \&quot;node-role.kubernetes.io/control-plane=&#39;&#39; (deprecated)\&quot;\n[mark-control-plane] Marking the node k8s-master-01.k8scluster.kubeinit.local as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]\n[bootstrap-token] Using token: 5cnmnj.eszt5v78ppqq3fia\n[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[bootstrap-token] Creating the \&quot;cluster-info\&quot; ConfigMap in the \&quot;kube-public\&quot; namespace\n[kubelet-finalize] Updating \&quot;/etc/kubernetes/kubelet.conf\&quot; to point to a rotatable kubelet client certificate and key\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\nYour Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nAlternatively, if you are the root user, you can run:\n\n  export KUBECONFIG=/etc/kubernetes/admin.conf\n\nYou should now deploy a pod network to the cluster.\nRun \&quot;kubectl apply -f [podnetwork].yaml\&quot; with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nYou can now join any number of the control-plane node running the following command on each as root:\n\n  kubeadm join api.k8scluster.kubeinit.local:6443 --token 5cnmnj.eszt5v78ppqq3fia \\\n    --discovery-token-ca-cert-hash sha256:d5feb7c990f86294f5f184c01d62b07a548ac4f84bbf5be7f6a39c50dc3dd5ac \\\n    --control-plane --certificate-key 9a35db48225db308b55357b491956f4b1f0f2da14be9d9b5d9a7d6dde87064ae\n\nPlease note that the certificate-key gives access to cluster sensitive data, keep it secret!\nAs a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use\n\&quot;kubeadm init phase upload-certs --upload-certs\&quot; to reload certs afterward.\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join api.k8scluster.kubeinit.local:6443 --token 5cnmnj.eszt5v78ppqq3fia \\\n    --discovery-token-ca-cert-hash sha256:d5feb7c990f86294f5f184c01d62b07a548ac4f84bbf5be7f6a39c50dc3dd5ac &quot;</span><span class="p">,</span>
    <span class="nt">&quot;stdout_lines&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;[preflight] Running pre-flight checks&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[reset] No etcd config found. Assuming external etcd&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[reset] Please, manually reset etcd to prevent further issues&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[reset] Stopping the kubelet service&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[reset] Unmounting mounted directories in \&quot;/var/lib/kubelet\&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[reset] Deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki]&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[reset] Deleting contents of stateful directories: [/var/lib/dockershim /var/run/kubernetes /var/lib/cni]&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;The reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;The reset process does not reset or clean up iptables rules or IPVS tables.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;If you wish to reset iptables, you must do so manually by using the \&quot;iptables\&quot; command.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;If your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)&quot;</span><span class="p">,</span>
        <span class="s2">&quot;to reset your system&#39;s IPVS tables.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;The reset process does not clean your kubeconfig files and you must remove them manually.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Please, check the contents of the $HOME/.kube/config file.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[init] Using Kubernetes version: v1.20.6&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[preflight] Running pre-flight checks&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[preflight] Pulling images required for setting up a Kubernetes cluster&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[preflight] This might take a minute or two, depending on the speed of your internet connection&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[preflight] You can also perform this action in beforehand using &#39;kubeadm config images pull&#39;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[certs] Using certificateDir folder \&quot;/etc/kubernetes/pki\&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[certs] Generating \&quot;ca\&quot; certificate and key&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[certs] Generating \&quot;apiserver\&quot; certificate and key&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[certs] apiserver serving cert is signed for DNS names [api.k8scluster.kubeinit.local k8s-master-01.k8scluster.kubeinit.local kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.0.0.1]&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[certs] Generating \&quot;apiserver-kubelet-client\&quot; certificate and key&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[certs] Generating \&quot;front-proxy-ca\&quot; certificate and key&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[certs] Generating \&quot;front-proxy-client\&quot; certificate and key&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[certs] Generating \&quot;etcd/ca\&quot; certificate and key&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[certs] Generating \&quot;etcd/server\&quot; certificate and key&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[certs] etcd/server serving cert is signed for DNS names [k8s-master-01.k8scluster.kubeinit.local localhost] and IPs [10.0.0.1 127.0.0.1 ::1]&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[certs] Generating \&quot;etcd/peer\&quot; certificate and key&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[certs] etcd/peer serving cert is signed for DNS names [k8s-master-01.k8scluster.kubeinit.local localhost] and IPs [10.0.0.1 127.0.0.1 ::1]&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[certs] Generating \&quot;etcd/healthcheck-client\&quot; certificate and key&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[certs] Generating \&quot;apiserver-etcd-client\&quot; certificate and key&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[certs] Generating \&quot;sa\&quot; key and public key&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[kubeconfig] Using kubeconfig folder \&quot;/etc/kubernetes\&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[kubeconfig] Writing \&quot;admin.conf\&quot; kubeconfig file&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[kubeconfig] Writing \&quot;kubelet.conf\&quot; kubeconfig file&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[kubeconfig] Writing \&quot;controller-manager.conf\&quot; kubeconfig file&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[kubeconfig] Writing \&quot;scheduler.conf\&quot; kubeconfig file&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[kubelet-start] Writing kubelet environment file with flags to file \&quot;/var/lib/kubelet/kubeadm-flags.env\&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[kubelet-start] Writing kubelet configuration to file \&quot;/var/lib/kubelet/config.yaml\&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[kubelet-start] Starting the kubelet&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[control-plane] Using manifest folder \&quot;/etc/kubernetes/manifests\&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[control-plane] Creating static Pod manifest for \&quot;kube-apiserver\&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[control-plane] Creating static Pod manifest for \&quot;kube-controller-manager\&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[control-plane] Creating static Pod manifest for \&quot;kube-scheduler\&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[etcd] Creating static Pod manifest for local etcd in \&quot;/etc/kubernetes/manifests\&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \&quot;/etc/kubernetes/manifests\&quot;. This can take up to 4m0s&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[kubelet-check] Initial timeout of 40s passed.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[apiclient] All control plane components are healthy after 72.042992 seconds&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[upload-config] Storing the configuration used in ConfigMap \&quot;kubeadm-config\&quot; in the \&quot;kube-system\&quot; Namespace&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[kubelet] Creating a ConfigMap \&quot;kubelet-config-1.20\&quot; in namespace kube-system with the configuration for the kubelets in the cluster&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[upload-certs] Storing the certificates in Secret \&quot;kubeadm-certs\&quot; in the \&quot;kube-system\&quot; Namespace&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[upload-certs] Using certificate key:&quot;</span><span class="p">,</span>
        <span class="s2">&quot;9a35db48225db308b55357b491956f4b1f0f2da14be9d9b5d9a7d6dde87064ae&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[mark-control-plane] Marking the node k8s-master-01.k8scluster.kubeinit.local as control-plane by adding the labels \&quot;node-role.kubernetes.io/master=&#39;&#39;\&quot; and \&quot;node-role.kubernetes.io/control-plane=&#39;&#39; (deprecated)\&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[mark-control-plane] Marking the node k8s-master-01.k8scluster.kubeinit.local as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[bootstrap-token] Using token: 5cnmnj.eszt5v78ppqq3fia&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[bootstrap-token] Creating the \&quot;cluster-info\&quot; ConfigMap in the \&quot;kube-public\&quot; namespace&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[kubelet-finalize] Updating \&quot;/etc/kubernetes/kubelet.conf\&quot; to point to a rotatable kubelet client certificate and key&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[addons] Applied essential addon: CoreDNS&quot;</span><span class="p">,</span>
        <span class="s2">&quot;[addons] Applied essential addon: kube-proxy&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Your Kubernetes control-plane has initialized successfully!&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;To start using your cluster, you need to run the following as a regular user:&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;  mkdir -p $HOME/.kube&quot;</span><span class="p">,</span>
        <span class="s2">&quot;  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config&quot;</span><span class="p">,</span>
        <span class="s2">&quot;  sudo chown $(id -u):$(id -g) $HOME/.kube/config&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Alternatively, if you are the root user, you can run:&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;  export KUBECONFIG=/etc/kubernetes/admin.conf&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;You should now deploy a pod network to the cluster.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Run \&quot;kubectl apply -f [podnetwork].yaml\&quot; with one of the options listed at:&quot;</span><span class="p">,</span>
        <span class="s2">&quot;  https://kubernetes.io/docs/concepts/cluster-administration/addons/&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;You can now join any number of the control-plane node running the following command on each as root:&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;  kubeadm join api.k8scluster.kubeinit.local:6443 --token 5cnmnj.eszt5v78ppqq3fia \\&quot;</span><span class="p">,</span>
        <span class="s2">&quot;    --discovery-token-ca-cert-hash sha256:d5feb7c990f86294f5f184c01d62b07a548ac4f84bbf5be7f6a39c50dc3dd5ac \\&quot;</span><span class="p">,</span>
        <span class="s2">&quot;    --control-plane --certificate-key 9a35db48225db308b55357b491956f4b1f0f2da14be9d9b5d9a7d6dde87064ae&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Please note that the certificate-key gives access to cluster sensitive data, keep it secret!&quot;</span><span class="p">,</span>
        <span class="s2">&quot;As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use&quot;</span><span class="p">,</span>
        <span class="s2">&quot;\&quot;kubeadm init phase upload-certs --upload-certs\&quot; to reload certs afterward.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Then you can join any number of worker nodes by running the following on each as root:&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="s2">&quot;kubeadm join api.k8scluster.kubeinit.local:6443 --token 5cnmnj.eszt5v78ppqq3fia \\&quot;</span><span class="p">,</span>
        <span class="s2">&quot;    --discovery-token-ca-cert-hash sha256:d5feb7c990f86294f5f184c01d62b07a548ac4f84bbf5be7f6a39c50dc3dd5ac &quot;</span>
    <span class="p">]</span>
<span class="p">}</span>
</pre></div>

                    </td>
                </tr>
                
            </tbody>
        </table>
    </div>
</div>

            </section>
            <section class="pf-c-page__main-section">
            </section>
        </main>
    </div>
</body>

</html>